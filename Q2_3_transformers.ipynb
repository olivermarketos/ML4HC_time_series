{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import json\n",
    "plt.style.use('default')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Sets the seed for reproducibility in PyTorch, NumPy, and Python.\"\"\"\n",
    "    random.seed(seed_value)  # Python random module\n",
    "    np.random.seed(seed_value) # Numpy module\n",
    "    torch.manual_seed(seed_value) # PyTorch CPU seeding\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # if you are using multi-GPU.\n",
    "        # Configure CuDNN for deterministic operations\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        # Optional: Newer PyTorch versions might require this for full determinism\n",
    "        # Note: This can sometimes throw errors if a deterministic implementation isn't available\n",
    "        # try:\n",
    "        #     torch.use_deterministic_algorithms(True)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Warning: Could not enable deterministic algorithms: {e}\")\n",
    "        # Optional: Sometimes needed for deterministic matrix multiplication\n",
    "        # os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "    print(f\"Seed set globally to {seed_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved to helper_funcs.py for better organization\n",
    "from helper_funcs import get_data_loaders, get_model, train_model, evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set globally to 42\n",
      "Model type selected:  tuple\n",
      "Model name:  tuple_model_30_changed_representation_2025-04-06\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration file with all hyperparameters, model parameters, data paths, etc.\n",
    "# for tuple: config_tupe_default.yaml\n",
    "# for time_grid: config_time_grid_default.yaml\n",
    "\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['device'] =\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "seed = config[\"seed\"]\n",
    "set_seed(seed_value=seed)\n",
    "\n",
    "date = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# SET MODEL NAME\n",
    "model_name = f\"{config['model_type']}_model_{config['epochs']}_changed_representation_{date}\"\n",
    "config['model_name'] = model_name\n",
    "\n",
    "print(\"Model type selected: \", config[\"model_type\"])\n",
    "print(\"Model name: \", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformers\n",
    "- Two transformer architectures were used\n",
    "  - time_grid: for question 3.2a, data is in 49 hour rows with 41 measurement columns\n",
    "  - tuples: for question3.2b, data is in tuples of (time, measurement, value) and each row is a measurement for a patient\n",
    "\n",
    "\n",
    "- Load prefered model by either:\n",
    "- 1. Changing `\"model_type\"` in config file or\n",
    "- 2. `config[\"model_type] = \"tuple\"  # Choose 'time_grid' or 'tuple'` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple Data: Train Patients: 4000, Val Patients: 4000, Test Patients: 4000\n",
      "Using 41 modalities (including padding index 0\n",
      "Labels - Train: 4000 (Positive: 554), Val: 4000 (Positive: 568), Test: 4000 (Positive: 585)\n",
      "DataLoaders created.\n",
      "Model (tuple) created and moved to cuda.\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/courses/ml4h/project1env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (-1.0000 -> 0.6821). Saving model...\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.6821 -> 0.7323). Saving model...\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7323 -> 0.7331). Saving model...\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7331 -> 0.7454). Saving model...\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7454 -> 0.7625). Saving model...\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7625 -> 0.7704). Saving model...\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (2/7)\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (3/7)\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7704 -> 0.7750). Saving model...\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7750 -> 0.7785). Saving model...\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7785 -> 0.7807). Saving model...\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7807 -> 0.7855). Saving model...\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (2/7)\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (3/7)\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (4/7)\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7855 -> 0.7879). Saving model...\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7879 -> 0.7885). Saving model...\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (2/7)\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (3/7)\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7885 -> 0.7886). Saving model...\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7886 -> 0.7889). Saving model...\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC improved (0.7889 -> 0.7903). Saving model...\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (1/7)\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AuROC did not improve. (2/7)\n",
      "\n",
      "--- Loading Best Model for Testing ---\n",
      "\n",
      "--- Evaluating on Test Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "Test Loss: 0.4522\n",
      "Test AuROC: 0.8039\n",
      "Test AuPRC: 0.4416\n",
      "Confusion Matrix:\n",
      "[[2943  472]\n",
      " [ 269  316]]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "train_loader, val_loader, test_loader = get_data_loaders(config)\n",
    "\n",
    "# 2. Model Initialization, Criterion, Optimizer\n",
    "model = get_model(config)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=config[\"scheduler_patience\"])\n",
    "\n",
    "# 3. Training Loop\n",
    "best_val_auroc = -1.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# check if the output directory exists, if not create it\n",
    "if not os.path.exists(config[\"output_dir\"]):\n",
    "    os.makedirs(config[\"output_dir\"])\n",
    "    print(f\"Output directory {config['output_dir']} created.\")\n",
    "    \n",
    "best_model_path = os.path.join(config[\"output_dir\"], f\"{config['model_name']}.pth\")\n",
    "num_epoch_trained = 0\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "    train_loss = train_model(model, train_loader, criterion, optimizer, config[\"device\"], config[\"model_type\"])\n",
    "    val_loss, val_auroc, val_auprc, _ = evaluate(model, val_loader, criterion, config[\"device\"], config[\"model_type\"])\n",
    "\n",
    "    scheduler.step(val_auroc)\n",
    "\n",
    "    if val_auroc > best_val_auroc:\n",
    "        print(f\"Validation AuROC improved ({best_val_auroc:.4f} -> {val_auroc:.4f}). Saving model...\")\n",
    "        best_val_auroc = val_auroc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"Validation AuROC did not improve. ({epochs_no_improve}/{config['early_stopping_patience']})\")\n",
    "\n",
    "    if epochs_no_improve >= config[\"early_stopping_patience\"]:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "            break\n",
    "    num_epoch_trained += 1\n",
    "\n",
    "config[\"num_epoch_trained\"] = num_epoch_trained\n",
    "#save the config file with the number of epochs trained\n",
    "config_path = os.path.join(config[\"output_dir\"], f\"config_{model_name}.yaml\")\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "# 4. Load Best Model and Evaluate on Test Set\n",
    "print(\"\\n--- Loading Best Model for Testing ---\")\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=config[\"device\"]))\n",
    "\n",
    "    print(\"\\n--- Evaluating on Test Set ---\")\n",
    "    test_loss, test_auroc, test_auprc, cm = evaluate(model, test_loader, criterion, config[\"device\"], config[\"model_type\"])\n",
    "    print(\"\\n--- Test Results ---\")\n",
    "\n",
    "else:\n",
    "    print(f\"Warning: Best model file not found at {best_model_path}. Testing with the last state.\")\n",
    "    # Optionally evaluate the final model state if no best model was saved\n",
    "    print(\"\\n--- Evaluating Last Model State on Test Set ---\")\n",
    "    test_loss, test_auroc, test_auprc, cm = evaluate(model, test_loader, criterion, config[\"device\"], config[\"model_type\"])\n",
    "    print(\"\\n--- Test Results (Last Epoch Model) ---\")\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test AuROC: {test_auroc:.4f}\")\n",
    "print(f\"Test AuPRC: {test_auprc:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "print(\"--------------------\")\n",
    "# Save results to json\n",
    "results = {\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_auroc\": test_auroc,\n",
    "    \"test_auprc\": test_auprc,\n",
    "    \"confusion_matrix\": cm.tolist(),  # Convert numpy array to list for JSON serialization\n",
    "}\n",
    "results_path = os.path.join(config[\"output_dir\"], f\"results_{model_name}.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
