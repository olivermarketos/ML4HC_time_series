{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building up on Question 2.1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "# Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve, auc\n",
    "\n",
    "# Statistics\n",
    "from scipy.stats import skew, kurtosis, randint\n",
    "\n",
    "# Modeling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    average_precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "static_variables = ['RecordID', 'Age', 'Gender', 'Height', 'ICUType', 'Weight']\n",
    "\n",
    "static_variables.remove('ICUType')\n",
    "\n",
    "static_variables_we_want = ['Age', 'Gender', 'Height', 'Weight']\n",
    "all_variables = ['Weight', 'Age', 'TroponinI', 'DiasABP', 'MechVent', 'HCO3', 'Cholesterol', 'HCT', 'SaO2', 'WBC', 'SysABP', 'Urine', 'ICUType', 'Gender', 'ALP', 'Creatinine', 'K', 'AST', 'Glucose', 'RespRate', 'MAP', 'FiO2', 'BUN', 'Na', 'Bilirubin', 'TroponinT', 'PaCO2', 'Height', 'GCS', 'HR', 'pH', 'PaO2', 'Lactate', 'ALT', 'NISysABP', 'RecordID', 'Platelets', 'Temp', 'Mg', 'NIDiasABP', 'Albumin', 'NIMAP']\n",
    "dyn_variables = [x for x in all_variables if x not in static_variables]\n",
    "dyn_variables.remove('ICUType')\n",
    "dyn_variables.append('Weight_VAR')\n",
    "len(dyn_variables), len(static_variables_we_want)\n",
    "\n",
    "initial_column_lists = static_variables_we_want + dyn_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import parquet file \n",
    "df_a =pd.read_parquet('data/processed_raw_data_set-a_1.parquet', engine='pyarrow')\n",
    "df_b =pd.read_parquet('data/processed_raw_data_set-b_1.parquet', engine='pyarrow')\n",
    "df_c =pd.read_parquet('data/processed_raw_data_set-c_1.parquet', engine='pyarrow')\n",
    "\n",
    "drop_ICUType = True \n",
    "if drop_ICUType:\n",
    "    df_a = df_a.drop(columns=['ICUType'])\n",
    "    df_b = df_b.drop(columns=['ICUType'])\n",
    "    df_c = df_c.drop(columns=['ICUType'])\n",
    "\n",
    "\n",
    "#  drop Time variable in df_a\n",
    "if 'Time' in df_a.columns:\n",
    "    df_a = df_a.drop(columns=['Time'])\n",
    "    df_b = df_b.drop(columns=['Time'])\n",
    "    df_c = df_c.drop(columns=['Time'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing features vectors of our patient\n",
    "\n",
    "Instead of working on the table where the missing values had already been filled, i prefer working on the not filled table because otherwise filled values would be taken into the mean and might flatten patient with lots of missing values. Then I compute the mean of variables for eahc patient over the 49 timestamps. \n",
    "\n",
    "Then i compute the median on the resulting table to fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 37, 41)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(static_variables_we_want) , len(dyn_variables), len(static_variables_we_want) + len(dyn_variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define aggregation functions\n",
    "agg_funcs = {col: ['mean','std','max','min','skew'] for col in dyn_variables}  \n",
    "\n",
    "agg_funcs['RecordID'] = 'first'  # Keep RecordID\n",
    "for stat_var in static_variables_we_want:\n",
    "    if stat_var in df_a.columns:\n",
    "        agg_funcs[stat_var] = 'first'  # Keep static variables\n",
    "\n",
    "# Compute mean and std in one go\n",
    "df_a_agg = df_a.groupby('RecordID').agg(agg_funcs)\n",
    "\n",
    "df_a_agg.columns = ['_'.join(col).strip() for col in df_a_agg.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for df_b \n",
    "agg_funcs = {col: ['mean','std','max','min','skew'] for col in dyn_variables}\n",
    "agg_funcs['RecordID'] = 'first'  # Keep RecordID\n",
    "for stat_var in static_variables_we_want:\n",
    "    if stat_var in df_b.columns:\n",
    "        agg_funcs[stat_var] = 'first'  # Keep static variables\n",
    "\n",
    "# Compute mean and std in one go\n",
    "df_b_agg = df_b.groupby('RecordID').agg(agg_funcs)\n",
    "\n",
    "df_b_agg.columns = ['_'.join(col).strip() for col in df_b_agg.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for df_c\n",
    "agg_funcs = {col: ['mean','std','max','min','skew'] for col in dyn_variables}\n",
    "agg_funcs['RecordID'] = 'first'  # Keep RecordID\n",
    "for stat_var in static_variables_we_want:\n",
    "    if stat_var in df_c.columns:\n",
    "        agg_funcs[stat_var] = 'first'  # Keep static variables\n",
    "\n",
    "# Compute mean and std in one go\n",
    "df_c_agg = df_c.groupby('RecordID').agg(agg_funcs)\n",
    "df_c_agg.columns = ['_'.join(col).strip() for col in df_c_agg.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute median of df_a \n",
    "\n",
    "df_a_agg_median = df_a_agg.median()\n",
    "\n",
    "# fill missing values with median\n",
    "df_a_agg.fillna(df_a_agg_median, inplace=True)\n",
    "\n",
    "df_b_agg.fillna(df_a_agg_median, inplace=True)\n",
    "df_c_agg.fillna(df_a_agg_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df_a_agg: ['Cholesterol_skew']\n"
     ]
    }
   ],
   "source": [
    "# (df_a_agg.isnull().sum() != 0 ) print where true\n",
    "# print columns with missing values\n",
    "missing_values_a = df_a_agg.isnull().sum() != 0\n",
    "#  print only where true\n",
    "missing_values_a = missing_values_a[missing_values_a].index.tolist()\n",
    "print(\"Missing values in df_a_agg:\", missing_values_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df_b_agg: ['Cholesterol_skew']\n"
     ]
    }
   ],
   "source": [
    "missing_values_b = df_b_agg.isnull().sum() != 0\n",
    "#  print only where true\n",
    "missing_values_b = missing_values_b[missing_values_b].index.tolist()\n",
    "print(\"Missing values in df_b_agg:\", missing_values_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in df_c_agg: ['Cholesterol_skew']\n"
     ]
    }
   ],
   "source": [
    "missing_values_c = df_c_agg.isnull().sum() != 0\n",
    "#  print only where true\n",
    "missing_values_c = missing_values_c[missing_values_c].index.tolist()\n",
    "print(\"Missing values in df_c_agg:\", missing_values_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Cholesterol_skew in df_a_agg, df_b_agg, df_c_agg\n",
    "df_a_agg = df_a_agg.drop(columns=['Cholesterol_skew'])\n",
    "df_b_agg = df_b_agg.drop(columns=['Cholesterol_skew'])\n",
    "df_c_agg = df_c_agg.drop(columns=['Cholesterol_skew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2110, 1471)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_a_agg['Weight_VAR_mean'].unique()), len(df_a_agg['Weight_VAR_std'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_a_agg.isnull().sum().sum() == 0\n",
    "assert df_b_agg.isnull().sum().sum() == 0\n",
    "assert df_c_agg.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes to parquet files\n",
    "df_a_agg.to_parquet('data/set_a_for_q2_1_more_feat.parquet', engine='pyarrow', index=False)\n",
    "df_b_agg.to_parquet('data/set_b_for_q2_1_more_feat.parquet', engine='pyarrow', index=False)\n",
    "df_c_agg.to_parquet('data/set_c_for_q2_1_more_feat.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
