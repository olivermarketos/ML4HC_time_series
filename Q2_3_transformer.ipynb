{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 4\n"
     ]
    }
   ],
   "source": [
    "static_variables = ['RecordID', 'Age', 'Gender', 'Height', 'ICUType', 'Weight']\n",
    "static_variables_we_want = ['Age', 'Gender', 'Height', 'Weight']\n",
    "all_variables = ['Weight', 'Age', 'TroponinI', 'DiasABP', 'MechVent', 'HCO3', 'Cholesterol', 'HCT', 'SaO2', 'WBC', 'SysABP', 'Urine', 'ICUType', 'Gender', 'ALP', 'Creatinine', 'K', 'AST', 'Glucose', 'RespRate', 'MAP', 'FiO2', 'BUN', 'Na', 'Bilirubin', 'TroponinT', 'PaCO2', 'Height', 'GCS', 'HR', 'pH', 'PaO2', 'Lactate', 'ALT', 'NISysABP', 'RecordID', 'Platelets', 'Temp', 'Mg', 'NIDiasABP', 'Albumin', 'NIMAP']\n",
    "dyn_variables = [x for x in all_variables if x not in static_variables]\n",
    "dyn_variables.append('Weight_VAR')\n",
    "\n",
    "print(len(dyn_variables), len(static_variables_we_want))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/set-a_no_nan.parquet\")\n",
    "val_df = pd.read_parquet(\"data/set-b_no_nan.parquet\")\n",
    "test_df = pd.read_parquet(\"data/set-c_no_nan.parquet\")\n",
    "\n",
    "outcomes_a_df = pd.read_csv(\"data/Outcomes-a.txt\", sep=\",\")\n",
    "outcomes_b_df = pd.read_csv(\"data/Outcomes-b.txt\", sep=\",\")\n",
    "outcomes_c_df = pd.read_csv(\"data/Outcomes-c.txt\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,) <class 'numpy.ndarray'>\n",
      "(4000,) <class 'numpy.ndarray'>\n",
      "(4000,) <class 'numpy.ndarray'>\n",
      "All records in outcomes and data are in same order\n"
     ]
    }
   ],
   "source": [
    "tmp_outcomes = [outcomes_a_df, outcomes_b_df, outcomes_c_df]\n",
    "\n",
    "data_df = [train_df, val_df, test_df]\n",
    "\n",
    "outcome_labels = []\n",
    "for i in range(3):\n",
    "    outcome_records = tmp_outcomes[i]['RecordID'].unique().astype(int)\n",
    "    train_records = data_df[i]['RecordID'].unique().astype(int)\n",
    "    assert (outcome_records - train_records == 0).all(), \"Mismatch: expected difference of 0 between outcome_records and train_records.\"\n",
    "\n",
    "    outcome_labels.append(tmp_outcomes[i][\"In-hospital_death\"].values) # 1 if patient died in hospital, 0 otherwise\n",
    "    print(outcome_labels[i].shape, type(outcome_labels[i]))\n",
    "print(\"All records in outcomes and data are in same order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 49, 41) (4000, 49, 41) (4000, 49, 41)\n"
     ]
    }
   ],
   "source": [
    "# Convert dfs into numpy arrays\n",
    "def convert_df_to_np(df):\n",
    "    dfs = []\n",
    "    for record_id in df['RecordID'].unique():\n",
    "        df_tmp = df[df['RecordID'] == record_id]\n",
    "        df_tmp = df_tmp.drop(columns=['RecordID', \"Time\"])\n",
    "        arr = df_tmp.to_numpy()\n",
    "        dfs.append(arr)\n",
    "\n",
    "    # convert list of dfs to list of tensors\n",
    "    train_data = np.array(dfs)\n",
    "    return train_data\n",
    "\n",
    "train_data = convert_df_to_np(data_df[0])\n",
    "val_data = convert_df_to_np(data_df[1])\n",
    "test_data = convert_df_to_np(data_df[2])\n",
    "\n",
    "# Standardize data\n",
    "mean = train_data.mean(axis=(0,1), keepdims=True)\n",
    "std = train_data.std(axis=(0,1), keepdims=True)\n",
    "std[std == 0] = 1.0\n",
    "\n",
    "\n",
    "# 2. Standardize data\n",
    "train_data = (train_data - mean) / std\n",
    "val_data = (val_data - mean) / std  \n",
    "test_data = (test_data - mean) / std  #\n",
    "\n",
    "print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MedicalTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MedicalTimeSeriesDataset(train_data, outcome_labels[0])\n",
    "val_dataset = MedicalTimeSeriesDataset(val_data, outcome_labels[1])\n",
    "test_dataset = MedicalTimeSeriesDataset(test_data, outcome_labels[2])\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_length=49):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_length, d_model) # max_length: number tokens, d_model: dimension of each token (embedding dim)\n",
    "\n",
    "        position = torch.arange(0, max_length).unsqueeze(1) # shape (max_length, 1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2)* -(torch.log(torch.tensor(10000.0)) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        self.pe: torch.Tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_dim = 41, d_model = 128, nhead = 4, num_layers = 2,dropout=0.1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=False)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.d_model = d_model # Store d_model for classifier input dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2) # transformer expects (seq_len, batch, features)\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # --- Global Average Pooling ---\n",
    "        # Average across the sequence length dimension (dim=0)\n",
    "        x = x.mean(dim=0) # (batch, d_model) e.g., (64, 128)\n",
    "        # --- Alternative: Use Last Time Step ---\n",
    "        # x = x[-1, :, :] # (batch, d_model) e.g., (64, 128)\n",
    "        # ---------------------------------------\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olivermarketos/miniconda3/envs/mybase/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated pos_weight: 4.0000 (Negatives=3446, Positives=554)\n",
      "Starting training for 20 epochs...\n",
      "Epoch 01/20\n",
      "  Train Loss: 0.8061\n",
      "  Val Loss: 0.7923, Val Acc (at 0.5): 0.8538, Val ROC-AUC: 0.8231\n",
      "  Validation ROC-AUC improved (0.0000 --> 0.8231). Saving model...\n",
      "Epoch 02/20\n",
      "  Train Loss: 0.7226\n",
      "  Val Loss: 0.7163, Val Acc (at 0.5): 0.7997, Val ROC-AUC: 0.8282\n",
      "  Validation ROC-AUC improved (0.8231 --> 0.8282). Saving model...\n",
      "Epoch 03/20\n",
      "  Train Loss: 0.6918\n",
      "  Val Loss: 0.6991, Val Acc (at 0.5): 0.7712, Val ROC-AUC: 0.8378\n",
      "  Validation ROC-AUC improved (0.8282 --> 0.8378). Saving model...\n",
      "Epoch 04/20\n",
      "  Train Loss: 0.6565\n",
      "  Val Loss: 0.6754, Val Acc (at 0.5): 0.8010, Val ROC-AUC: 0.8478\n",
      "  Validation ROC-AUC improved (0.8378 --> 0.8478). Saving model...\n",
      "Epoch 05/20\n",
      "  Train Loss: 0.6221\n",
      "  Val Loss: 0.7523, Val Acc (at 0.5): 0.8415, Val ROC-AUC: 0.8375\n",
      "  Validation ROC-AUC did not improve. Patience 1/5\n",
      "Epoch 06/20\n",
      "  Train Loss: 0.6174\n",
      "  Val Loss: 0.7098, Val Acc (at 0.5): 0.8150, Val ROC-AUC: 0.8439\n",
      "  Validation ROC-AUC did not improve. Patience 2/5\n",
      "Epoch 07/20\n",
      "  Train Loss: 0.5785\n",
      "  Val Loss: 0.7072, Val Acc (at 0.5): 0.7987, Val ROC-AUC: 0.8381\n",
      "  Validation ROC-AUC did not improve. Patience 3/5\n",
      "Epoch 08/20\n",
      "  Train Loss: 0.5558\n",
      "  Val Loss: 0.7473, Val Acc (at 0.5): 0.8313, Val ROC-AUC: 0.8304\n",
      "  Validation ROC-AUC did not improve. Patience 4/5\n",
      "Epoch 09/20\n",
      "  Train Loss: 0.5227\n",
      "  Val Loss: 0.7947, Val Acc (at 0.5): 0.8313, Val ROC-AUC: 0.8271\n",
      "  Validation ROC-AUC did not improve. Patience 5/5\n",
      "  Early stopping triggered after 9 epochs.\n",
      "\n",
      "Training finished.\n",
      "Loading best model saved with ROC-AUC: 0.8478\n",
      "\n",
      "Evaluating on test set with the loaded best model...\n",
      "\n",
      "Test set evaluation:\n",
      "Test Loss: 0.7475, Test Acc (at 0.5): 0.7953, Test ROC-AUC: 0.8116\n"
     ]
    }
   ],
   "source": [
    "model = TimeSeriesTransformer(num_layers=3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else  \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "n_samples = len(outcome_labels[0])\n",
    "n_positives = sum(outcome_labels[0])\n",
    "n_negatives = n_samples - n_positives\n",
    "\n",
    "if n_positives > 0:\n",
    "    pos_weight_val = n_negatives / n_positives\n",
    "else:\n",
    "    pos_weight_val = 1.0 # Or handle as an error if appropriate\n",
    "pos_weight_val = 4.0\n",
    "\n",
    "print(f\"Calculated pos_weight: {pos_weight_val:.4f} (Negatives={n_negatives}, Positives={n_positives})\")\n",
    "pos_weight = torch.tensor([pos_weight_val], dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01) # Added weight decay\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Validation/testing function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = [] # Store raw outputs (logits)\n",
    "    all_targets = [] # Store targets\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch).squeeze() # raw logits\n",
    "\n",
    "            # Ensure y_batch has the same shape as outputs if squeeze() removed a dim\n",
    "            if outputs.dim() == 0: # Handle batch size of 1 if squeezed to scalar\n",
    "                 outputs = outputs.unsqueeze(0)\n",
    "            if y_batch.dim() > outputs.dim(): # Ensure y_batch has same shape as output\n",
    "                y_batch = y_batch.squeeze()\n",
    "            elif outputs.dim() > y_batch.dim(): # This shouldn't happen with .squeeze() above but safety check\n",
    "                outputs = outputs.squeeze() # Re-try squeeze if needed\n",
    "\n",
    "            # Ensure shapes match before loss calculation\n",
    "            if outputs.shape != y_batch.shape:\n",
    "                 # This indicates a potential issue elsewhere, maybe with batch size 1 handling\n",
    "                 print(f\"Shape mismatch: outputs {outputs.shape}, y_batch {y_batch.shape}\")\n",
    "                 # Decide how to handle: skip batch, reshape if possible, etc.\n",
    "                 # For now, we'll just report loss can't be computed for this batch\n",
    "                 continue # Skip this batch if shapes don't match\n",
    "\n",
    "\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    all_outputs = np.array(all_outputs)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "  # Apply sigmoid to logits to get probabilities for thresholding\n",
    "    probs = 1 / (1 + np.exp(-all_outputs)) # Sigmoid function\n",
    "    preds_labels = (probs >= 0.5).astype(int) # Threshold probabilities\n",
    "\n",
    "    # Ensure targets are integers for accuracy score\n",
    "    all_targets = all_targets.astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, preds_labels)\n",
    "    # ROC AUC can be calculated directly from logits (or probabilities)\n",
    "    # Check if there's more than one class present in targets for ROC AUC\n",
    "    if len(np.unique(all_targets)) > 1:\n",
    "        roc_auc = roc_auc_score(all_targets, all_outputs) # Use logits directly\n",
    "    else:\n",
    "        roc_auc = 0.5 # Or np.nan, indicating AUC is not defined\n",
    "        print(f\"Warning: Only one class present in targets. ROC AUC set to {roc_auc}\")\n",
    "\n",
    "\n",
    "    return avg_loss, accuracy, roc_auc\n",
    "\n",
    "    \n",
    "num_epochs = 20 # Increase epochs, rely on saving the best\n",
    "best_val_roc_auc = 0.0 # Initialize low for maximization\n",
    "patience_counter = 0\n",
    "patience = 5 # Number of epochs to wait for improvement before stopping\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy, val_roc_auc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch:02d}/{num_epochs}')\n",
    "    print(f'  Train Loss: {train_loss:.4f}')\n",
    "    print(f'  Val Loss: {val_loss:.4f}, Val Acc (at 0.5): {val_accuracy:.4f}, Val ROC-AUC: {val_roc_auc:.4f}') # Label accuracy as potentially misleading\n",
    "\n",
    "    # Save best model based on validation ROC-AUC\n",
    "    if val_roc_auc > best_val_roc_auc:\n",
    "        print(f'  Validation ROC-AUC improved ({best_val_roc_auc:.4f} --> {val_roc_auc:.4f}). Saving model...')\n",
    "        best_val_roc_auc = val_roc_auc # Correctly update the best AUC score\n",
    "        torch.save(model.state_dict(), 'best_transformer_model.pt')\n",
    "        patience_counter = 0 # Reset patience counter\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'  Validation ROC-AUC did not improve. Patience {patience_counter}/{patience}')\n",
    "\n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f'  Early stopping triggered after {epoch} epochs.')\n",
    "        break # Exit the training loop\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "\n",
    "# Load best model (make sure the file exists)\n",
    "print(f\"Loading best model saved with ROC-AUC: {best_val_roc_auc:.4f}\")\n",
    "try:\n",
    "    model.load_state_dict(torch.load('best_transformer_model.pt'))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'best_transformer_model.pt' not found. Was a model ever saved?\")\n",
    "    # Handle error appropriately - maybe exit or proceed with the last state of the model?\n",
    "\n",
    "# Evaluate on test set\n",
    "print('\\nEvaluating on test set with the loaded best model...')\n",
    "test_loss, test_accuracy, test_roc_auc = evaluate(model, test_loader, criterion, device)\n",
    "print('\\nTest set evaluation:')\n",
    "# Remind that accuracy uses 0.5 threshold\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc (at 0.5): {test_accuracy:.4f}, Test ROC-AUC: {test_roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding optimal threshold on validation set...\n",
      "Optimal threshold based on max F1 score on validation set: 0.5538\n",
      "Optimal threshold based on max Youden's J on validation set: 0.4659\n",
      "\n",
      "Evaluating on test set using threshold: 0.4659\n",
      "\n",
      "Test set evaluation (with optimized threshold):\n",
      "Test Loss: 0.7475\n",
      "Test ROC-AUC: 0.8116\n",
      "Test Accuracy: 0.7675\n",
      "Test Precision: 0.3480\n",
      "Test Recall: 0.6752\n",
      "Test F1-Score: 0.4593\n"
     ]
    }
   ],
   "source": [
    "# --- After loading the best model ---\n",
    "print(\"\\nFinding optimal threshold on validation set...\")\n",
    "model.eval() # Ensure model is in eval mode\n",
    "val_logits = []\n",
    "val_targets_list = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        val_logits.extend(outputs.cpu().numpy())\n",
    "        val_targets_list.extend(y_batch.cpu().numpy())\n",
    "\n",
    "val_logits = np.array(val_logits)\n",
    "val_targets_np = np.array(val_targets_list).astype(int)\n",
    "val_probs = 1 / (1 + np.exp(-val_logits))\n",
    "\n",
    "# Method 1: Maximize F1 score\n",
    "precision, recall, thresholds_pr = precision_recall_curve(val_targets_np, val_probs)\n",
    "# Calculate F1 score, handling potential division by zero\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-8)\n",
    "# thresholds_pr correspond to precision/recall pairs, need to adjust index\n",
    "optimal_idx_f1 = np.argmax(f1_scores)\n",
    "optimal_threshold_f1 = thresholds_pr[optimal_idx_f1]\n",
    "print(f\"Optimal threshold based on max F1 score on validation set: {optimal_threshold_f1:.4f}\")\n",
    "\n",
    "# Method 2: Maximize Youden's J (sensitivity + specificity - 1)\n",
    "fpr, tpr, thresholds_roc = roc_curve(val_targets_np, val_probs)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx_j = np.argmax(youden_j)\n",
    "optimal_threshold_j = thresholds_roc[optimal_idx_j]\n",
    "print(f\"Optimal threshold based on max Youden's J on validation set: {optimal_threshold_j:.4f}\")\n",
    "\n",
    "# Choose one threshold (e.g., from F1)\n",
    "optimal_threshold =  optimal_threshold_j # or optimal_threshold_f1 \n",
    "\n",
    "# --- Now, evaluate on the TEST set using the optimal threshold ---\n",
    "\n",
    "def evaluate_with_threshold(model, loader, criterion, device, threshold):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_outputs = [] # Store raw outputs (logits)\n",
    "    all_targets = [] # Store targets\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # (Same loop as before to get all_outputs and all_targets)\n",
    "        for X_batch, y_batch in loader:\n",
    "            # ... (identical data loading and model prediction) ...\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch).squeeze() # raw logits\n",
    "\n",
    "            if outputs.dim() == 0: outputs = outputs.unsqueeze(0)\n",
    "            if y_batch.dim() > outputs.dim(): y_batch = y_batch.squeeze()\n",
    "            elif outputs.dim() > y_batch.dim(): outputs = outputs.squeeze()\n",
    "\n",
    "            if outputs.shape != y_batch.shape:\n",
    "                 print(f\"Shape mismatch: outputs {outputs.shape}, y_batch {y_batch.shape}\")\n",
    "                 continue\n",
    "\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "\n",
    "    all_outputs = np.array(all_outputs)\n",
    "    all_targets = np.array(all_targets)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "    # Apply sigmoid and OPTIMAL threshold\n",
    "    probs = 1 / (1 + np.exp(-all_outputs))\n",
    "    preds_labels = (probs >= threshold).astype(int) # Use the optimal threshold\n",
    "\n",
    "    all_targets = all_targets.astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, preds_labels)\n",
    "    roc_auc = roc_auc_score(all_targets, all_outputs) if len(np.unique(all_targets)) > 1 else 0.5\n",
    "\n",
    "    # Calculate other metrics\n",
    "    precision = precision_score(all_targets, preds_labels, zero_division=0)\n",
    "    recall = recall_score(all_targets, preds_labels, zero_division=0)\n",
    "    f1 = f1_score(all_targets, preds_labels, zero_division=0)\n",
    "\n",
    "    return avg_loss, accuracy, roc_auc, precision, recall, f1\n",
    "\n",
    "\n",
    "# Evaluate on test set using the found threshold\n",
    "print(f'\\nEvaluating on test set using threshold: {optimal_threshold:.4f}')\n",
    "test_loss, test_accuracy, test_roc_auc, test_precision, test_recall, test_f1 = evaluate_with_threshold(\n",
    "    model, test_loader, criterion, device, optimal_threshold\n",
    ")\n",
    "\n",
    "print('\\nTest set evaluation (with optimized threshold):')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test ROC-AUC: {test_roc_auc:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Precision: {test_precision:.4f}')\n",
    "print(f'Test Recall: {test_recall:.4f}')\n",
    "print(f'Test F1-Score: {test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finding optimal threshold on validation set...\n",
    "Optimal threshold based on max F1 score on validation set: 0.5538\n",
    "Optimal threshold based on max Youden's J on validation set: 0.4659\n",
    "\n",
    "Evaluating on test set using threshold: 0.5538\n",
    "\n",
    "Test set evaluation (with optimized threshold):\n",
    "Test Loss: 0.7475\n",
    "Test ROC-AUC: 0.8116\n",
    "Test Accuracy: 0.8225\n",
    "Test Precision: 0.4181\n",
    "Test Recall: 0.5453\n",
    "Test F1-Score: 0.4733"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mybase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
